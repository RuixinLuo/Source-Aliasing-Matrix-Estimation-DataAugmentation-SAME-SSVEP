{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load module\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import warnings\n",
    "from scipy import signal\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def corr2(a, b):\n",
    "    \"\"\" Solving for the two-dimensional correlation coefficient\n",
    "    :param a: \n",
    "    :param b: \n",
    "\n",
    "    :return: correlation coefficient\n",
    "    \"\"\"\n",
    "    \n",
    "    a = a - np.sum(a) / np.size(a)\n",
    "    b = b - np.sum(b) / np.size(b)\n",
    "    r = (a * b).sum() / math.sqrt((a * a).sum() * (b * b).sum())\n",
    "    return r\n",
    "\n",
    "def acc_calculate(predict):\n",
    "    \"\"\" Calculate accuracy\n",
    "    :param predict:  (n_trial,n_event)\n",
    "\n",
    "    :return: acc\n",
    "    \"\"\"\n",
    "    \n",
    "    [nTrials, nEvents] = predict.shape  \n",
    "    label_target = np.ones((nTrials, 1)) * np.arange(0, nEvents, 1, int)\n",
    "    logical_right = (label_target == predict)\n",
    "    acc_num = np.sum(logical_right != 0)\n",
    "    acc = acc_num / nTrials / nEvents\n",
    "    return acc\n",
    "\n",
    "class PreProcessing_BETA():\n",
    "    \"\"\"\n",
    "    Adapted from Orion Han\n",
    "    https://github.com/OrionHH/BrainOn-an-online-brain-computer-interface-BCI-framework\n",
    "    \"\"\"\n",
    "    \n",
    "    CHANNELS = [\n",
    "        'FP1','FPZ','FP2','AF3','AF4','F7','F5','F3',\n",
    "        'F1','FZ','F2','F4','F6','F8','FT7','FC5',\n",
    "        'FC3','FC1','FCZ','FC2','FC4','FC6','FC8','T7',\n",
    "        'C5','C3','C1','CZ','C2','C4','C6','T8',\n",
    "        'M1','TP7','CP5','CP3','CP1','CPZ','CP2','CP4',\n",
    "        'CP6','TP8','M2','P7','P5','P3','P1','PZ',\n",
    "        'P2','P4','P6','P8','PO7','PO5','PO3','POZ',\n",
    "        'PO4','PO6','PO8','CB1','O1','OZ','O2','CB2'\n",
    "    ] # M1: 33. M2: 43.\n",
    "\n",
    "    def __init__(self, filepath,  t_begin, t_end, n_classes=40, fs_down=250, chans=None, num_filter=1):\n",
    "\n",
    "        self.filepath = filepath\n",
    "        self.fs_down = fs_down\n",
    "        self.t_begin = t_begin\n",
    "        self.t_end = t_end\n",
    "        self.chans = chans\n",
    "        self.n_classes = n_classes\n",
    "        self.num_filter = num_filter\n",
    "\n",
    "    def load_data(self):\n",
    "        '''\n",
    "        Application: load data and selected channels by chans.\n",
    "\n",
    "        :param chans: list | None\n",
    "        :return: raw_data: 4-D, numpy\n",
    "            n_chans * n_samples * n_classes * n_trials\n",
    "\n",
    "        '''\n",
    "        raw_mat = sio.loadmat(self.filepath)\n",
    "        raw_data11 = raw_mat['data']  \n",
    "        data = raw_data11[0,0]['EEG']\n",
    "        raw_data = np.transpose(data,[0,1,3,2]) # n_chans * n_samples * n_classes * n_trials\n",
    "\n",
    "        idx_loc = list()\n",
    "        if isinstance(self.chans, list):\n",
    "            for _, char_value in enumerate(self.chans):\n",
    "                idx_loc.append(self.CHANNELS.index(char_value.upper()))\n",
    "\n",
    "        raw_data = raw_data[idx_loc, : , : , :] if idx_loc else raw_data\n",
    "\n",
    "        self.raw_fs = 250  # .mat sampling rate\n",
    "\n",
    "        return raw_data\n",
    "\n",
    "    def resample_data(self, raw_data):\n",
    "        '''\n",
    "        :param raw_data: from method load_data.\n",
    "        :return: raw_data_resampled, 4-D, numpy\n",
    "            n_chans * n_samples * n_classes * n_trials\n",
    "        '''\n",
    "        if self.raw_fs > self.fs_down:\n",
    "            raw_data_resampled = signal.resample(raw_data, round(self.fs_down*raw_data.shape[1]/self.raw_fs), axis=1)\n",
    "        elif self.raw_fs < self.fs_down:\n",
    "            warnings.warn('You are up-sampling, no recommended')\n",
    "            raw_data_resampled = signal.resample(raw_data, round(self.fs_down*raw_data.shape[1]/self.raw_fs), axis=1)\n",
    "        else:\n",
    "            raw_data_resampled = raw_data\n",
    "\n",
    "        return raw_data_resampled\n",
    "\n",
    "    def _get_iir_sos_band(self, w_pass, w_stop):\n",
    "        '''\n",
    "        Get second-order sections (like 'ba') of Chebyshev type I filter.\n",
    "        :param w_pass: list, 2 elements\n",
    "        :param w_stop: list, 2 elements\n",
    "        :return: sos_system\n",
    "            i.e the filter coefficients.\n",
    "        '''\n",
    "        if len(w_pass) != 2 or len(w_stop) != 2:\n",
    "            raise ValueError('w_pass and w_stop must be a list with 2 elements.')\n",
    "\n",
    "        if w_pass[0] > w_pass[1] or w_stop[0] > w_stop[1]:\n",
    "            raise ValueError('Element 1 must be greater than Element 0 for w_pass and w_stop.')\n",
    "\n",
    "        if w_pass[0] < w_stop[0] or w_pass[1] > w_stop[1]:\n",
    "            raise ValueError('It\\'s a band-pass iir filter, please check the values between w_pass and w_stop.')\n",
    "\n",
    "        wp = [2 * w_pass[0] / self.fs_down, 2 * w_pass[1] / self.fs_down]\n",
    "        ws = [2 * w_stop[0] / self.fs_down, 2 * w_stop[1] / self.fs_down]\n",
    "        gpass = 4  \n",
    "        gstop = 30  # dB\n",
    "\n",
    "        N, wn = signal.cheb1ord(wp, ws, gpass=gpass, gstop=gstop)\n",
    "        sos_system = signal.cheby1(N, rp=0.5, Wn=wn, btype='bandpass', output='sos')\n",
    "\n",
    "        return sos_system\n",
    "\n",
    "\n",
    "    def filtered_data_iir111(self, w_pass_2d, w_stop_2d, data):\n",
    "        '''\n",
    "        filter data by IIR, which parameters are set by method _get_iir_sos_band in BasePreProcessing class.\n",
    "        :param w_pass_2d: 2-d, numpy,\n",
    "            w_pass_2d[0, :]: w_pass[0] of method _get_iir_sos_band,\n",
    "            w_pass_2d[1, :]: w_pass[1] of method _get_iir_sos_band.\n",
    "        :param w_stop_2d: 2-d, numpy,\n",
    "            w_stop_2d[0, :]: w_stop[0] of method _get_iir_sos_band,\n",
    "            w_stop_2d[1, :]: w_stop[1] of method _get_iir_sos_band.\n",
    "        :param data: 4-d, numpy, from method load_data or resample_data.\n",
    "            n_chans * n_samples * n_classes * n_trials\n",
    "        :return: filtered_data: dict,\n",
    "            {'bank1': values1, 'bank2': values2, ...,'bank'+str(num_filter): values}\n",
    "            values1, values2,...: 4-D, numpy, n_chans * n_samples * n_classes * n_trials.\n",
    "        e.g.\n",
    "        w_pass_2d = np.array([[5, 14, 22, 30, 38, 46, 54],[70, 70, 70, 70, 70, 70, 70]])\n",
    "        w_stop_2d = np.array([[3, 12, 20, 28, 36, 44, 52],[72, 72, 72, 72, 72, 72, 72]])\n",
    "        '''\n",
    "        if w_pass_2d.shape != w_stop_2d.shape:\n",
    "            raise ValueError('The shape of w_pass_2d and w_stop_2d should be equal.')\n",
    "        if self.num_filter > w_pass_2d.shape[1]:\n",
    "            raise ValueError('num_filter should be less than or equal to w_pass_2d.shape[1]')\n",
    "\n",
    "        begin_point, end_point = int(np.ceil(self.t_begin * self.fs_down)), int(np.ceil(self.t_end * self.fs_down) + 1)\n",
    "        data = data[:,begin_point:end_point,:,:]\n",
    "\n",
    "        sos_system = dict()\n",
    "        filtered_data = dict()\n",
    "        for idx_filter in range(self.num_filter):\n",
    "            sos_system['filter'+str(idx_filter+1)] = self._get_iir_sos_band(w_pass=[w_pass_2d[0, idx_filter], w_pass_2d[1, idx_filter]],\n",
    "                                                                            w_stop=[w_stop_2d[0, idx_filter],\n",
    "                                                                                    w_stop_2d[1, idx_filter]])\n",
    "            filter_data = signal.sosfiltfilt(sos_system['filter' + str(idx_filter + 1)], data, axis=1)\n",
    "            filtered_data['bank'+str(idx_filter+1)] = filter_data\n",
    "\n",
    "        return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRCs_estimation(data, mean_target):\n",
    "    \"\"\" source signal estimation\n",
    "\n",
    "    :param data: n_channel_1, n_times\n",
    "    :param mean_target: n_channel_2, n_times\n",
    "\n",
    "    :return: data_after: n_channel_2, n_times\n",
    "    \"\"\"\n",
    "    \n",
    "    nChannel, nTimes = np.shape(data)\n",
    "    X_a = data\n",
    "    X = mean_target\n",
    "\n",
    "    # solve PT\n",
    "    PT = X @ X_a.T @ np.linalg.inv(X_a @ X_a.T)\n",
    "    data_after = PT @ X_a\n",
    "\n",
    "    return data_after\n",
    "\n",
    "def get_augment_fb_noiseAfter(fs, f, Nh_start, Nh_end, ntrail_noise, mean_temp):\n",
    "    \"\"\"  Artificially generated signals by SAME\n",
    "\n",
    "    :param fs: Sampling rate\n",
    "    :param f:  the frequency of signal\n",
    "    :param Nh_start: Minimum number of harmonics\n",
    "    :param Nh_end: Maximum number of harmonics\n",
    "    :param ntrial_noise: Number of generated signals\n",
    "    :param mean_temp: n_channel, n_times\n",
    "\n",
    "    :return: data_aug: n_channel, n_times, ntrial_noise\n",
    "    \"\"\"\n",
    "    \n",
    "    Nh_step  = np.arange(Nh_start,Nh_end+1,1)\n",
    "    Nh = Nh_step.shape[-1]\n",
    "    nChannel, nTime = mean_temp.shape\n",
    "    #  Generate reference signal Yf\n",
    "    Ts = 1 / fs\n",
    "    n = np.arange(nTime) * Ts\n",
    "    Yf = np.zeros((nTime, 2*Nh))   \n",
    "    flag = 0\n",
    "    for iNh in Nh_step:\n",
    "        y_sin = np.sin(2 * np.pi * f * iNh * n)\n",
    "        Yf[:, flag * 2] = y_sin\n",
    "        y_cos = np.cos(2 * np.pi * f * iNh  * n)\n",
    "        Yf[:, flag * 2 + 1] = y_cos\n",
    "        flag = flag + 1\n",
    "\n",
    "    Z = TRCs_estimation(Yf.T, mean_temp)\n",
    "    # get vars of Z\n",
    "    vars = np.zeros((Z.shape[0],Z.shape[0]))\n",
    "    for i_c in range(nChannel):\n",
    "        vars[i_c,i_c] = np.var(Z[i_c,:])\n",
    "\n",
    "    # add noise\n",
    "    data_aug = np.zeros((nChannel, nTime, ntrail_noise))\n",
    "    for i_aug in range(ntrail_noise):\n",
    "        # Randomly generated noise\n",
    "        Datanosie = np.random.multivariate_normal(mean=np.zeros((nChannel)), cov=vars, size =  nTime)\n",
    "        data_aug[:,:,i_aug] = Z + 0.05 * Datanosie.T\n",
    "\n",
    "    return data_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TRCA\n",
    "def trca_matrix(data):\n",
    "    \"\"\" Task-related component analysis (TRCA)\n",
    "    :param data: Multi-trial EEG signals under the same task\n",
    "           ndarray(n_channels, n_sample_points, n_trials)\n",
    "\n",
    "    :return: w: spatial filter\n",
    "           ndarray(n_channels, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    X = data\n",
    "\n",
    "    # X_mean = X.mean(axis=1, keepdims=True)\n",
    "    # X = X - X_mean\n",
    "\n",
    "    nChans = X.shape[0]\n",
    "    nTimes = X.shape[1]\n",
    "    nTrial = X.shape[2]\n",
    "    #  solve S\n",
    "    S = np.zeros((nChans, nChans))\n",
    "    for i in range(nTrial):\n",
    "        for j in range(nTrial):\n",
    "            if (i != j):\n",
    "                x_i = X[:, :, i]\n",
    "                x_j = X[:, :, j]\n",
    "                S = S + np.dot(x_i, (x_j.T))\n",
    "    #  solve Q\n",
    "    X1 = X.reshape([nChans, nTimes * nTrial], order='F')  \n",
    "    Q = X1 @ X1.T\n",
    "    \n",
    "    #  get eigenvector\n",
    "    b = np.dot(np.linalg.inv(Q), S)\n",
    "    [eig_value, eig_w] = np.linalg.eig(b)  # in matlabï¼ša/b = inv(a)*b\n",
    "\n",
    "    # Descending order\n",
    "    eig_w = eig_w[:, eig_value.argsort()[::-1]]  # return indices in ascending order and reverse\n",
    "    eig_value.sort()\n",
    "    eig_value = eig_value[::-1]  # sort in descending\n",
    "\n",
    "    w = eig_w[:, 0]\n",
    "    return w.real\n",
    "\n",
    "def TRCA_train(trainData):\n",
    "    \"\"\" Get TRCA spatial filters and average templates for all classes\n",
    "    :param trainData: training data of all events\n",
    "            ndarray(n_channels, n_sample_points, n_events, n_trials)\n",
    "\n",
    "    :return: w: (n_channels, n_events)\n",
    "             mean_temp (n_channels, n_sample_points, n_events)\n",
    "    \"\"\"\n",
    "    \n",
    "    [nChannels, nTimes, nEvents, nTrials] = trainData.shape \n",
    "    # get w of event class\n",
    "    w = np.zeros((nChannels, nEvents))\n",
    "    for i in range(nEvents):\n",
    "        w_data = trainData[:, :, i, :]\n",
    "        w1 = trca_matrix(w_data)\n",
    "        w[:, i] = w1\n",
    "    # get mean temps\n",
    "    mean_temp = np.zeros((nChannels, nTimes, nEvents))\n",
    "    mean_temp = np.mean(trainData, -1)\n",
    "    return w, mean_temp\n",
    "\n",
    "def TRCA_test(testData, w, mean_temp, ensemble):\n",
    "    \"\"\"\n",
    "    :param testData: test_data of multi trials\n",
    "           ndarray(n_channels, n_sample_points, n_trials(equals to n_events))\n",
    "    :param w: Spatial Filters\n",
    "           ndarray (n_channels, n_events)\n",
    "    :param mean_temp: Average template\n",
    "           ndarray (n_channels, n_sample_points, n_events)\n",
    "    :param ensemble: bool\n",
    "\n",
    "    :return: predict of singe block\n",
    "           ndarray(n_trials, n_classes)\n",
    "    \"\"\"\n",
    "    \n",
    "    [nChannels, nTimes, nEvents] = testData.shape\n",
    "    rr = np.zeros((nEvents, nEvents))\n",
    "    for m in range(nEvents):  # the m-th test data\n",
    "        test = testData[:, :, m]\n",
    "        # Calculate the vector of correlation coefficients\n",
    "        r = np.zeros(nEvents)\n",
    "        for n in range(nEvents):  # the n-th train model\n",
    "            train = mean_temp[:, :, n]\n",
    "            if ensemble is True:\n",
    "                r[n] = corr2(train.T @ w, test.T @ w)\n",
    "            else:\n",
    "                r[n] = corr2(train.T @ w[:, n], test.T @ w[:, n])\n",
    "        rr[m, :] = r\n",
    "    return rr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TDCA\n",
    "def get_P(f_list, Nh, sTime, sfreq):\n",
    "    \"\"\" Get the projection matrix P for all classes\n",
    "    :param f_list: the frequency of all events\n",
    "    :param Nh: number of harmonics\n",
    "    :param sTime: signal duration\n",
    "    :param sfreq: sampling rate\n",
    "\n",
    "    :return: P: the projection matrix P for all classes\n",
    "             ndarray(n_Times, n_Times, n_Events)\n",
    "    \"\"\"\n",
    "    \n",
    "    nEvent = f_list.shape[0]\n",
    "    P = np.zeros((int(sTime * sfreq), int(sTime * sfreq), nEvent))\n",
    "    for iievent in range(nEvent):\n",
    "        #  Generate reference signal Yf\n",
    "        f = f_list[iievent]\n",
    "        nTime = int(sTime * sfreq)\n",
    "        Ts = 1 / sfreq\n",
    "        n = np.arange(nTime) * Ts\n",
    "        Yf = np.zeros((nTime, 2 * Nh)) \n",
    "        for iNh in range(Nh):\n",
    "            y_sin = np.sin(2 * np.pi * f * (iNh + 1) * n)\n",
    "            Yf[:, iNh * 2] = y_sin\n",
    "            y_cos = np.cos(2 * np.pi * f * (iNh + 1) * n)\n",
    "            Yf[:, iNh * 2 + 1] = y_cos\n",
    "        q, _ = np.linalg.qr(Yf, mode='reduced')\n",
    "        P[:,:,iievent] = q @ q.T\n",
    "\n",
    "    return P\n",
    "\n",
    "def tdca_matrix(data, Nk):\n",
    "    \"\"\" Task-discriminant component analysis (TDCA)\n",
    "    :param data: training data of all events\n",
    "           ndarray(n_channels * (l + 1), 2*n_points,  n_events, n_trials)\n",
    "    :param Nk: the number of subspaces\n",
    "           int\n",
    "\n",
    "    :return: w: Spatial Filters\n",
    "           ndarray(n_channels * (l + 1), Nk)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_aug_2 = np.transpose(data,[2,3,0,1])  # nEvents, nTrials, nChannels * (l + 1), 2*npoints\n",
    "    [n_events, n_trials, _, _] = X_aug_2.shape\n",
    "    # get Sb\n",
    "    class_center = X_aug_2.mean(axis=1)  # # nEvents , nChannels * (l + 1), 2*npoints\n",
    "    total_center = class_center.mean(axis=0,keepdims=True)  # # 1, nChannels * (l + 1), 2*npoints\n",
    "    Hb = class_center - total_center  # Broadcasting in numpy\n",
    "    Sb = np.einsum('ecp, ehp->ch', Hb, Hb)\n",
    "    Sb /= n_events\n",
    "    # get Sw\n",
    "    class_center = np.expand_dims(class_center, 1) # nEvents , 1, nChannels * (l + 1), 2*npoints\n",
    "    Hw = X_aug_2 - np.tile(class_center,[1, n_trials,1,1]) # nEvents , nTrials, nChannels * (l + 1), 2*npoints\n",
    "    Sw = np.einsum('etcp, ethp->ch', Hw, Hw)\n",
    "    Sw /= (n_events * n_trials)\n",
    "    Sw = 0.001 * np.eye(Hw.shape[2]) + Sw   # regularization\n",
    "    #  get eigenvector\n",
    "    b = np.dot(np.linalg.inv(Sw), Sb)\n",
    "    [eig_value, eig_w] = np.linalg.eig(b) \n",
    "\n",
    "    # Descending order\n",
    "    eig_w = eig_w[:, eig_value.argsort()[::-1]]  # return indices in ascending order and reverse\n",
    "    eig_value.sort()\n",
    "    eig_value = eig_value[::-1]  # sort in descending\n",
    "    w = eig_w[:, :Nk]\n",
    "\n",
    "    return w  \n",
    "\n",
    "def TDCA_train(trainData, P ,l , Nk ):\n",
    "    \"\"\" Get TDCA spatial filters and average templates for all classes\n",
    "    :param trainData: training data of all events\n",
    "           ndarray(n_channels, (n_sample_points + l), n_events, n_trials)\n",
    "    :param P: projection matrix for all classes\n",
    "           ndarray(n_sample_points, n_sample_points, n_events)\n",
    "    :param l: delay point\n",
    "    :param Nk: the number of subspaces\n",
    "\n",
    "    :return: w: Spatial Filters\n",
    "           ndarray(n_channels * (l + 1), Nk)\n",
    "             mean_temp: average templates\n",
    "           ndarray(Nk, 2n_sample_points, n_events)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    [nChannels, nTimes, nEvents, nTrials] = trainData.shape \n",
    "    npoints = nTimes - l\n",
    "\n",
    "\n",
    "    data_aug_2 = np.zeros((nChannels * (l + 1), 2*npoints, nEvents, nTrials))\n",
    "    for ievent in range(nEvents):\n",
    "        dat = trainData[:, :, ievent,:]\n",
    "        # first\n",
    "        dat_aug_1 = np.zeros((nChannels*(l+1), npoints, nTrials))\n",
    "        for il in range(l+1):\n",
    "            dat_aug_1[il*(nChannels):(il+1)*nChannels, : ,: ] = dat[:,il:(il+npoints) ,:]\n",
    "        # second\n",
    "        dat_p = np.zeros_like((dat_aug_1))\n",
    "        for itrial in range(nTrials):\n",
    "            dat_p[:, :, itrial] = dat_aug_1[:, :, itrial] @ P[:, :, ievent]  # projection\n",
    "        dat_aug_2 = np.concatenate((dat_aug_1, dat_p), axis=1, out=None)\n",
    "        #\n",
    "        data_aug_2[..., ievent, :] = dat_aug_2\n",
    "\n",
    "    # get w\n",
    "    w = tdca_matrix(data_aug_2 , Nk=Nk)\n",
    "    # get mean temps   Nk * 2 Num of sample points * num of events\n",
    "    mean_tem = np.zeros((Nk, npoints*2, nEvents))\n",
    "    mean_data = np.mean(data_aug_2, -1)\n",
    "    for i in range((nEvents)):\n",
    "        mean_tem[:,:,i] = w.T @ mean_data[:,:,i]\n",
    "\n",
    "    return w, mean_tem\n",
    "\n",
    "def TDCA_test(testData, w, mean_temp ,P , l ):\n",
    "    \"\"\"\n",
    "    :param testData: test_data of multi trials\n",
    "           ndarray(n_channels, n_sample_points, n_trials(equals to n_events))\n",
    "    :param w: Spatial Filters\n",
    "           ndarray(n_channels * (l + 1), Nk)\n",
    "    :param mean_temp: Average template\n",
    "           ndarray(Nk, 2n_sample_points, n_events)\n",
    "    :param P:  projection matrix for all classes\n",
    "           ndarray(n_sample_points, n_sample_points, n_events)\n",
    "    :param l:  delay point\n",
    "\n",
    "    :return: predict of singe block\n",
    "           ndarray(n_trials, n_classes)\n",
    "    \"\"\"\n",
    "    \n",
    "    [nChannels, nTimes, nEvents] = testData.shape\n",
    "    rr = np.zeros((nEvents, nEvents))\n",
    "    for m in range(nEvents):  # the m-th test data\n",
    "        test = testData[:, :, m]\n",
    "        # first\n",
    "        test_aug_1 = np.zeros((nChannels * (l + 1), nTimes))\n",
    "        aug_zero = np.zeros((nChannels, l))  # Splice 0 matrix\n",
    "        test = np.concatenate((test, aug_zero), axis=1, out=None)  # nChannels, nTimes + l\n",
    "        for il in range(l + 1):\n",
    "            test_aug_1[il * (nChannels):(il + 1) * nChannels, :] = test[:, il:(il + nTimes)]\n",
    "        # Calculate the vector of correlation coefficients\n",
    "        r = np.zeros(nEvents)\n",
    "        for n in range(nEvents):  # the n-th train model\n",
    "            # second\n",
    "            dat_p = test_aug_1 @ P[:, :, n]\n",
    "            test_aug_2 = np.concatenate((test_aug_1, dat_p), axis=1, out=None)\n",
    "            # slove rr\n",
    "            train = mean_temp[:, :, n]\n",
    "            r[n] = corr2(train, w.T @ test_aug_2)\n",
    "        rr[m, :] = r\n",
    "    return rr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNT ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import scipy.io as sio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit,LeaveOneOut\n",
    "\n",
    "\n",
    "def beta_TDCA_Aug(idx_num, n_train, t_task ,n_Aug):\n",
    "\n",
    "    # setting\n",
    "    f_list = [8.6, 8.8,\n",
    "              9, 9.2, 9.4, 9.6, 9.8,\n",
    "              10, 10.2, 10.4, 10.6, 10.8,\n",
    "              11, 11.2, 11.4, 11.6, 11.8,\n",
    "              12, 12.2, 12.4, 12.6, 12.8,\n",
    "              13, 13.2, 13.4, 13.6, 13.8,\n",
    "              14, 14.2, 14.4, 14.6, 14.8,\n",
    "              15, 15.2, 15.4, 15.6, 15.8,\n",
    "              8, 8.2, 8.4, ]\n",
    "    f_list = np.array(f_list)\n",
    "    subject_id = ['S'+'{:02d}'.format(idx_subject+1) for idx_subject in range(70)] # S01,S02,.....S70\n",
    "\n",
    "    idx_num = idx_num\n",
    "    idx_subject = subject_id[idx_num]\n",
    "    sfreq = 250\n",
    "    filepath = r'Beta'  \n",
    "    filepath = os.path.join(filepath, str(idx_subject) + '.mat')\n",
    "    num_filter = 5\n",
    "    preEEG = PreProcessing_BETA(filepath, t_begin=0.5, t_end=0.5 + 0.13 + t_task + 3/sfreq,\n",
    "                           fs_down=250, chans=['POZ', 'PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'O1', 'OZ', 'O2'],\n",
    "                           num_filter=num_filter)\n",
    "\n",
    "    raw_data = preEEG.load_data()\n",
    "    w_pass_2d = np.array([[5, 14, 22, 30, 38], [90, 90, 90, 90, 90]])  # 70\n",
    "    w_stop_2d = np.array([[3, 12, 20, 28, 36], [92, 92, 92, 92, 92]])  # 72\n",
    "    filtered_data = preEEG.filtered_data_iir111(w_pass_2d, w_stop_2d, raw_data)\n",
    "\n",
    "    \"\"\"\n",
    "     Cross-validation parameter setting\n",
    "    \"\"\"\n",
    "    nBlock = 4\n",
    "    nEvent = 40\n",
    "    train_size = n_train  \n",
    "    n_splits = 4\n",
    "    if train_size == nBlock - 1:\n",
    "        kf = LeaveOneOut()\n",
    "    else:\n",
    "        kf = ShuffleSplit(n_splits=n_splits, train_size=train_size, random_state=idx_num + 1)\n",
    "\n",
    "    \"\"\"\n",
    "    TDCA parameter setting\n",
    "    \"\"\"\n",
    "    l = 3  # delay point \n",
    "    t = t_task\n",
    "    train_point  = np.arange(int((0.13) * sfreq), int((0.13 + t) * sfreq)+l)\n",
    "    test_point = np.arange(int((0.13) * sfreq), int((0.13 + t) * sfreq))\n",
    "    # get P of all classes\n",
    "    P = get_P(f_list=f_list, Nh=5, sTime=t, sfreq=sfreq)\n",
    "\n",
    "    # Cross-validation\n",
    "    acc_s = 0\n",
    "    for train, test in kf.split(np.arange(nBlock)):\n",
    "\n",
    "        # train : get ensembleW of banks\n",
    "        train_w = dict()\n",
    "        train_meantemp = dict()\n",
    "        for idx_filter in range(num_filter):\n",
    "            idx_filter += 1\n",
    "            bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "            train_data11 = bank_data[:, :, :, train]  # \n",
    "            train_data = train_data11[:, train_point, :, :]  # n_channel * n_times * n_events * n_trials\n",
    "            \n",
    "            if n_Aug == 0:\n",
    "                trainData_pt = train_data.copy()\n",
    "            else:            \n",
    "                # Data augmentation\n",
    "                ntrail_noise = n_Aug\n",
    "                data_augment = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2], ntrail_noise))\n",
    "                for ievent in range(nEvent):\n",
    "                    # get Nh_strat\n",
    "                    f = f_list[ievent]\n",
    "                    for ih in range(5):\n",
    "                        ih = ih+1\n",
    "                        if ih*f >= 8*idx_filter:\n",
    "                            Nh_start = ih\n",
    "                            break\n",
    "                    data_augment[:, :, ievent, :] = get_augment_fb_noiseAfter(fs=sfreq, f=f_list[ievent],Nh_start=Nh_start, Nh_end=5,\n",
    "                                                                ntrail_noise=ntrail_noise,\n",
    "                                                                mean_temp=np.mean(train_data,-1)[:, :, ievent])\n",
    "                trainData_pt = np.concatenate((train_data, data_augment), axis=3)\n",
    "\n",
    "            # train\n",
    "            w, mean_temp_TDCA = TDCA_train(trainData_pt, P=P, l=l, Nk=9)\n",
    "            #\n",
    "            train_w['bank' + str(idx_filter)] = w\n",
    "            train_meantemp['bank' + str(idx_filter)] = mean_temp_TDCA\n",
    "\n",
    "        # test:\n",
    "        predictAll = np.zeros((test.shape[0], nEvent))\n",
    "        flag = 0\n",
    "        for isplit in test:\n",
    "            rrall = np.zeros((nEvent, nEvent))\n",
    "            for idx_filter in range(num_filter):\n",
    "                idx_filter += 1\n",
    "                bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "                test_data111 = bank_data[:, :, :, isplit]\n",
    "                test_data = test_data111[:,test_point,:]\n",
    "                rr = TDCA_test(test_data, train_w['bank' + str(idx_filter)], train_meantemp['bank' + str(idx_filter)],\n",
    "                               P=P, l=l)\n",
    "                rrall += np.multiply(np.sign(rr), (rr ** 2)) * (idx_filter ** (-1.25) + 0.25)\n",
    "            predict = np.argmax(rrall, -1)\n",
    "            predictAll[flag, :] = predict\n",
    "            flag += 1\n",
    "        acc_s = acc_calculate(predictAll) + acc_s\n",
    "    acc = acc_s / n_splits\n",
    "    # print('sub', idx_num + 1, ', acc = ', acc_s / n_splits)\n",
    "    return acc\n",
    "\n",
    "def beta_eTRCA_Aug(idx_num, n_train, t_task ,n_Aug):\n",
    "\n",
    "    # setting\n",
    "    f_list = [8.6, 8.8,\n",
    "              9, 9.2, 9.4, 9.6, 9.8,\n",
    "              10, 10.2, 10.4, 10.6, 10.8,\n",
    "              11, 11.2, 11.4, 11.6, 11.8,\n",
    "              12, 12.2, 12.4, 12.6, 12.8,\n",
    "              13, 13.2, 13.4, 13.6, 13.8,\n",
    "              14, 14.2, 14.4, 14.6, 14.8,\n",
    "              15, 15.2, 15.4, 15.6, 15.8,\n",
    "              8, 8.2, 8.4, ]\n",
    "    subject_id = ['S'+'{:02d}'.format(idx_subject+1) for idx_subject in range(70)]  # S01,S02,...S70\n",
    "\n",
    "    idx_num = idx_num\n",
    "    idx_subject = subject_id[idx_num]\n",
    "    sfreq = 250\n",
    "    filepath = r'Beta'  \n",
    "    filepath = os.path.join(filepath, str(idx_subject) + '.mat')\n",
    "    num_filter = 5\n",
    "    preEEG = PreProcessing_BETA(filepath, t_begin=0.5, t_end=0.5 + 0.13 + t_task,  # t_begin=0.5+0.13, t_end=0.5+0.13+0.3\n",
    "                           fs_down=250, chans=['POZ', 'PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'O1', 'OZ', 'O2'],\n",
    "                           num_filter=num_filter)\n",
    "\n",
    "    raw_data = preEEG.load_data()\n",
    "    w_pass_2d = np.array([[5, 14, 22, 30, 38], [90, 90, 90, 90, 90]])  # 70\n",
    "    w_stop_2d = np.array([[3, 12, 20, 28, 36], [92, 92, 92, 92, 92]])  # 72\n",
    "    filtered_data = preEEG.filtered_data_iir111(w_pass_2d, w_stop_2d, raw_data)\n",
    "\n",
    "    \"\"\"\n",
    "     Cross-validation parameter setting\n",
    "    \"\"\"\n",
    "    nBlock = 4\n",
    "    nEvent = 40\n",
    "    train_size = n_train \n",
    "    n_splits = 4\n",
    "    if train_size == nBlock - 1:\n",
    "        kf = LeaveOneOut()\n",
    "    else:\n",
    "        kf = ShuffleSplit(n_splits=n_splits, train_size=train_size, random_state=idx_num + 1)\n",
    "\n",
    "    t = t_task\n",
    "    task_point = np.arange(int((0.13) * sfreq), int((0.13 + t) * sfreq))\n",
    "\n",
    "    # train : get ensembleW of banks\n",
    "    acc_s = 0\n",
    "    for train, test in kf.split(np.arange(nBlock)):\n",
    "\n",
    "        # train : get ensembleW of banks\n",
    "        train_w = dict()\n",
    "        train_meantemp = dict()\n",
    "        for idx_filter in range(num_filter):\n",
    "            idx_filter += 1\n",
    "            bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "            train_data11 = bank_data[:, :, :, train] \n",
    "            train_data = train_data11[:, task_point, :, :]  # n_channel * n_times * n_events * n_trials\n",
    "            \n",
    "            if n_Aug == 0:\n",
    "                trainData_pt = train_data.copy()\n",
    "            else:            \n",
    "                # Data augmentation\n",
    "                ntrail_noise = n_Aug\n",
    "                data_augment = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2], ntrail_noise))\n",
    "                for ievent in range(nEvent):\n",
    "                    # get Nh_strat\n",
    "                    f = f_list[ievent]\n",
    "                    for ih in range(5):\n",
    "                        ih = ih+1\n",
    "                        if ih*f >= 8*idx_filter:\n",
    "                            Nh_start = ih\n",
    "                            break\n",
    "                    data_augment[:, :, ievent, :] = get_augment_fb_noiseAfter(fs=sfreq, f=f_list[ievent],Nh_start=Nh_start, Nh_end=5,\n",
    "                                                                ntrail_noise=ntrail_noise,\n",
    "                                                                mean_temp=np.mean(train_data,-1)[:, :, ievent])\n",
    "                trainData_pt = np.concatenate((train_data, data_augment), axis=3)\n",
    "\n",
    "            # train\n",
    "            w, mean_temp = TRCA_train(trainData_pt)\n",
    "            #\n",
    "            train_w['bank' + str(idx_filter)] = w\n",
    "            train_meantemp['bank' + str(idx_filter)] = mean_temp\n",
    "\n",
    "        # test:\n",
    "        predictAll = np.zeros((test.shape[0], nEvent))\n",
    "        flag = 0\n",
    "        for isplit in test:\n",
    "            rrall = np.zeros((nEvent, nEvent))\n",
    "            for idx_filter in range(num_filter):\n",
    "                idx_filter += 1\n",
    "                bank_data = filtered_data['bank' + str(idx_filter)]\n",
    "                test_data = bank_data[:, :, :, isplit]\n",
    "                test_data = test_data[:, task_point, :]\n",
    "                rr = TRCA_test(test_data, train_w['bank' + str(idx_filter)],\n",
    "                               train_meantemp['bank' + str(idx_filter)], True)\n",
    "                rrall += np.multiply(np.sign(rr), (rr ** 2)) * (idx_filter ** (-1.25) + 0.25)\n",
    "            predict = np.argmax(rrall, -1)\n",
    "            predictAll[flag, :] = predict\n",
    "            flag += 1\n",
    "        acc_s = acc_calculate(predictAll) + acc_s\n",
    "    acc = acc_s / n_splits\n",
    "    # print('sub', idx_num + 1, ', acc = ', acc_s / n_splits)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRCA(w/oSAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size= 1\n",
      "time = 106.3842568397522  s\n",
      "[0.11458333 0.05208333 0.34166667 0.10833333 0.09791667 0.06041667\n",
      " 0.16666667 0.07916667 0.21458333 0.12916667 0.03333333 0.2375\n",
      " 0.36666667 0.06666667 0.03125    0.05416667 0.01666667 0.18125\n",
      " 0.08958333 0.05833333 0.13541667 0.06041667 0.31458333 0.10208333\n",
      " 0.17916667 0.06875    0.15       0.25416667 0.07708333 0.10416667\n",
      " 0.1625     0.04375    0.05625    0.09375    0.15416667 0.20416667\n",
      " 0.07916667 0.03333333 0.08333333 0.0375     0.07083333 0.23333333\n",
      " 0.05       0.04791667 0.04166667 0.06041667 0.03333333 0.13125\n",
      " 0.1125     0.05       0.10625    0.07291667 0.325      0.05625\n",
      " 0.03333333 0.40625    0.20416667 0.24166667 0.01041667 0.225\n",
      " 0.02708333 0.11875    0.15833333 0.11875    0.08333333 0.13958333\n",
      " 0.1        0.07916667 0.03541667 0.06666667]\n",
      "mean_acc: 0.11904761904761903\n",
      "train_size= 2\n",
      "time = 95.07941007614136  s\n",
      "[0.85     0.88125  0.68125  0.6125   0.665625 0.615625 0.621875 0.415625\n",
      " 0.865625 0.403125 0.125    0.684375 0.728125 0.584375 0.45625  0.446875\n",
      " 0.109375 0.878125 0.753125 0.309375 0.615625 0.709375 0.86875  0.540625\n",
      " 0.54375  0.165625 0.56875  0.5875   0.415625 0.715625 0.240625 0.184375\n",
      " 0.28125  0.73125  0.66875  0.746875 0.690625 0.084375 0.31875  0.584375\n",
      " 0.190625 0.60625  0.29375  0.165625 0.39375  0.275    0.1625   0.746875\n",
      " 0.734375 0.43125  0.403125 0.628125 0.503125 0.378125 0.20625  0.45625\n",
      " 0.81875  0.66875  0.0875   0.63125  0.103125 0.640625 0.815625 0.440625\n",
      " 0.14375  0.70625  0.79375  0.75     0.590625 0.76875 ]\n",
      "mean_acc: 0.5212053571428571\n",
      "train_size= 3\n",
      "time = 94.33243155479431  s\n",
      "[0.9     0.90625 0.775   0.70625 0.85    0.68125 0.73125 0.54375 0.91875\n",
      " 0.46875 0.2     0.75625 0.7875  0.7125  0.64375 0.55625 0.15625 0.90625\n",
      " 0.83125 0.44375 0.75625 0.75625 0.93125 0.65625 0.63125 0.20625 0.69375\n",
      " 0.65625 0.55625 0.825   0.38125 0.25625 0.375   0.8125  0.7875  0.80625\n",
      " 0.775   0.09375 0.525   0.675   0.2875  0.6875  0.425   0.2125  0.525\n",
      " 0.4875  0.23125 0.8     0.79375 0.54375 0.45    0.775   0.7     0.50625\n",
      " 0.24375 0.44375 0.81875 0.78125 0.1375  0.6875  0.1375  0.73125 0.9\n",
      " 0.58125 0.15    0.74375 0.88125 0.80625 0.70625 0.85   ]\n",
      "mean_acc: 0.609375\n"
     ]
    }
   ],
   "source": [
    "Aug_size = [0,0,0]\n",
    "acc_all = np.zeros((70,3))\n",
    "for i_train in range(3):\n",
    "    print('train_size=',i_train+1)\n",
    "    c = time.time()\n",
    "    acc = Parallel(n_jobs=-1)(delayed(beta_eTRCA_Aug)(idx_num, n_train=i_train+1, t_task=0.5, n_Aug=Aug_size[i_train]) for idx_num in range(70))\n",
    "    acc =  np.array(acc)\n",
    "    acc_all[:,i_train] = acc\n",
    "    e = time.time()\n",
    "    print('time =', e - c,' s')\n",
    "    print(acc)\n",
    "    print('mean_acc:',np.mean(acc))\n",
    "sio.savemat(r'demo_beta_eTRCA_withoutSAME.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRCA(W/SAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size= 1\n",
      "time = 99.01571726799011  s\n",
      "[0.83958333 0.83333333 0.67916667 0.5625     0.65416667 0.56041667\n",
      " 0.51041667 0.35625    0.86666667 0.41041667 0.11041667 0.66875\n",
      " 0.73958333 0.50833333 0.4875     0.53958333 0.14583333 0.83541667\n",
      " 0.64166667 0.32083333 0.62708333 0.72291667 0.81458333 0.5125\n",
      " 0.5625     0.21041667 0.61041667 0.56041667 0.45       0.725\n",
      " 0.3375     0.23125    0.2625     0.68125    0.63541667 0.7375\n",
      " 0.69791667 0.10208333 0.4625     0.50416667 0.1875     0.59375\n",
      " 0.3625     0.2        0.46666667 0.36875    0.1625     0.68541667\n",
      " 0.72708333 0.37083333 0.41041667 0.63541667 0.52291667 0.45208333\n",
      " 0.13125    0.4875     0.76875    0.59166667 0.17291667 0.6\n",
      " 0.15       0.65       0.84375    0.51041667 0.16875    0.6875\n",
      " 0.81458333 0.7375     0.66041667 0.72083333]\n",
      "mean_acc: 0.5222916666666666\n",
      "train_size= 2\n",
      "time = 97.92097282409668  s\n",
      "[0.909375 0.896875 0.746875 0.728125 0.83125  0.6875   0.70625  0.525\n",
      " 0.921875 0.509375 0.203125 0.74375  0.821875 0.66875  0.58125  0.5875\n",
      " 0.240625 0.875    0.853125 0.528125 0.75     0.828125 0.95     0.59375\n",
      " 0.646875 0.25625  0.71875  0.690625 0.640625 0.81875  0.4125   0.3125\n",
      " 0.40625  0.771875 0.828125 0.790625 0.78125  0.146875 0.615625 0.653125\n",
      " 0.3      0.6625   0.496875 0.271875 0.621875 0.575    0.24375  0.746875\n",
      " 0.75     0.53125  0.578125 0.753125 0.69375  0.553125 0.271875 0.4875\n",
      " 0.84375  0.7125   0.2      0.7125   0.175    0.70625  0.903125 0.65625\n",
      " 0.1875   0.7625   0.821875 0.80625  0.734375 0.85625 ]\n",
      "mean_acc: 0.625625\n",
      "train_size= 3\n",
      "time = 86.72654867172241  s\n",
      "[0.9125  0.93125 0.78125 0.80625 0.89375 0.7625  0.79375 0.6125  0.9375\n",
      " 0.575   0.2875  0.76875 0.85625 0.7375  0.6625  0.6625  0.31875 0.91875\n",
      " 0.8875  0.63125 0.81875 0.84375 0.95625 0.7125  0.68125 0.30625 0.78125\n",
      " 0.70625 0.71875 0.8625  0.44375 0.4     0.5     0.86875 0.80625 0.8125\n",
      " 0.83125 0.21875 0.6375  0.69375 0.3375  0.69375 0.53125 0.31875 0.68125\n",
      " 0.6875  0.325   0.8125  0.8     0.61875 0.58125 0.8     0.8     0.6125\n",
      " 0.3     0.4625  0.8625  0.7875  0.275   0.7625  0.2375  0.775   0.9375\n",
      " 0.71875 0.2375  0.80625 0.8875  0.81875 0.7625  0.91875]\n",
      "mean_acc: 0.6783928571428572\n"
     ]
    }
   ],
   "source": [
    "Aug_size = [3,5,6]\n",
    "acc_all = np.zeros((70,3))\n",
    "for i_train in range(3):\n",
    "    print('train_size=',i_train+1)\n",
    "    c = time.time()\n",
    "    acc = Parallel(n_jobs=-1)(delayed(beta_eTRCA_Aug)(idx_num, n_train=i_train+1, t_task=0.5, n_Aug=Aug_size[i_train]) for idx_num in range(70))\n",
    "    acc =  np.array(acc)\n",
    "    acc_all[:,i_train] = acc\n",
    "    e = time.time()\n",
    "    print('time =', e - c,' s')\n",
    "    print(acc)\n",
    "    print('mean_acc:',np.mean(acc))\n",
    "sio.savemat(r'demo_beta_eTRCA_withSAME.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDCA(w/oSAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size= 1\n",
      "time = 303.67482328414917  s\n",
      "[0.32291667 0.17083333 0.33958333 0.11666667 0.14791667 0.10416667\n",
      " 0.1375     0.14375    0.43333333 0.2        0.09166667 0.4125\n",
      " 0.44583333 0.08958333 0.08125    0.10833333 0.02083333 0.43125\n",
      " 0.23125    0.07916667 0.22291667 0.17083333 0.44583333 0.21666667\n",
      " 0.20416667 0.08541667 0.27083333 0.25833333 0.11458333 0.2375\n",
      " 0.2        0.01666667 0.09583333 0.22708333 0.22291667 0.32083333\n",
      " 0.225      0.0375     0.1125     0.09375    0.0875     0.30833333\n",
      " 0.07916667 0.09791667 0.0875     0.07916667 0.06666667 0.32291667\n",
      " 0.2875     0.06041667 0.19375    0.13958333 0.25625    0.07083333\n",
      " 0.05833333 0.39166667 0.27708333 0.25       0.07916667 0.29375\n",
      " 0.0375     0.15416667 0.26666667 0.18333333 0.07916667 0.18958333\n",
      " 0.19583333 0.2125     0.05833333 0.1625    ]\n",
      "mean_acc: 0.1844940476190476\n",
      "train_size= 2\n",
      "time = 222.89798712730408  s\n",
      "[0.925    0.915625 0.740625 0.721875 0.81875  0.634375 0.71875  0.540625\n",
      " 0.9375   0.46875  0.1125   0.690625 0.79375  0.671875 0.55625  0.51875\n",
      " 0.215625 0.890625 0.834375 0.546875 0.696875 0.796875 0.925    0.64375\n",
      " 0.671875 0.24375  0.675    0.628125 0.64375  0.834375 0.375    0.2875\n",
      " 0.328125 0.78125  0.778125 0.775    0.7      0.11875  0.575    0.628125\n",
      " 0.271875 0.61875  0.384375 0.215625 0.55625  0.51875  0.2625   0.759375\n",
      " 0.76875  0.503125 0.54375  0.73125  0.690625 0.50625  0.259375 0.803125\n",
      " 0.821875 0.7625   0.18125  0.690625 0.13125  0.678125 0.871875 0.65\n",
      " 0.15625  0.7625   0.815625 0.803125 0.684375 0.815625]\n",
      "mean_acc: 0.6082589285714286\n",
      "train_size= 3\n",
      "time = 155.24060249328613  s\n",
      "[0.9375  0.9375  0.78125 0.8     0.9125  0.75625 0.775   0.66875 0.95625\n",
      " 0.5625  0.225   0.7625  0.8375  0.7375  0.68125 0.6     0.325   0.90625\n",
      " 0.9125  0.7125  0.78125 0.84375 0.95625 0.7375  0.76875 0.34375 0.75\n",
      " 0.69375 0.7125  0.9125  0.44375 0.4     0.48125 0.85    0.83125 0.81875\n",
      " 0.8125  0.21875 0.66875 0.725   0.3625  0.675   0.50625 0.25    0.6625\n",
      " 0.6375  0.30625 0.84375 0.8125  0.6375  0.60625 0.8     0.8     0.5625\n",
      " 0.30625 0.9     0.88125 0.7875  0.25    0.75    0.2     0.7625  0.93125\n",
      " 0.7     0.18125 0.8125  0.9     0.86875 0.7125  0.86875]\n",
      "mean_acc: 0.6830357142857142\n"
     ]
    }
   ],
   "source": [
    "Aug_size = [0,0,0]\n",
    "acc_all = np.zeros((70,3))\n",
    "for i_train in range(3):\n",
    "    print('train_size=',i_train+1)\n",
    "    c = time.time()\n",
    "    acc = Parallel(n_jobs=-1)(delayed(beta_TDCA_Aug)(idx_num, n_train=i_train+1, t_task=0.5, n_Aug=Aug_size[i_train]) for idx_num in range(70))\n",
    "    acc =  np.array(acc)\n",
    "    acc_all[:,i_train] = acc\n",
    "    e = time.time()\n",
    "    print('time =', e - c,' s')\n",
    "    print(acc)\n",
    "    print('mean_acc:',np.mean(acc))\n",
    "sio.savemat(r'demo_beta_TDCA_withoutSAME.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDCA(w/SAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size= 1\n",
      "time = 303.69347047805786  s\n",
      "[0.80625    0.83125    0.68958333 0.61041667 0.75833333 0.52291667\n",
      " 0.66041667 0.36875    0.88958333 0.41041667 0.11875    0.66666667\n",
      " 0.7375     0.49375    0.47708333 0.46875    0.20833333 0.81666667\n",
      " 0.6875     0.37291667 0.64583333 0.64583333 0.82916667 0.55833333\n",
      " 0.53333333 0.26041667 0.59583333 0.56666667 0.46875    0.79791667\n",
      " 0.33125    0.23958333 0.29166667 0.70416667 0.64375    0.75416667\n",
      " 0.70416667 0.13541667 0.48958333 0.46041667 0.18541667 0.55\n",
      " 0.3375     0.19375    0.48958333 0.33958333 0.16458333 0.66458333\n",
      " 0.70416667 0.43958333 0.43333333 0.6125     0.62291667 0.42916667\n",
      " 0.18958333 0.67291667 0.70833333 0.6125     0.14583333 0.58958333\n",
      " 0.18333333 0.575      0.80833333 0.55833333 0.15625    0.69166667\n",
      " 0.81666667 0.68541667 0.54583333 0.72291667]\n",
      "mean_acc: 0.5297321428571431\n",
      "train_size= 2\n",
      "time = 235.44340467453003  s\n",
      "[0.93125  0.921875 0.74375  0.73125  0.85     0.6625   0.703125 0.5125\n",
      " 0.91875  0.540625 0.16875  0.725    0.80625  0.628125 0.575    0.56875\n",
      " 0.253125 0.8625   0.878125 0.565625 0.746875 0.825    0.95625  0.659375\n",
      " 0.684375 0.275    0.725    0.68125  0.6625   0.8875   0.434375 0.28125\n",
      " 0.39375  0.78125  0.796875 0.78125  0.809375 0.20625  0.63125  0.65\n",
      " 0.303125 0.646875 0.471875 0.259375 0.63125  0.515625 0.284375 0.771875\n",
      " 0.78125  0.575    0.575    0.71875  0.7125   0.534375 0.25625  0.759375\n",
      " 0.85     0.765625 0.23125  0.70625  0.20625  0.7      0.903125 0.709375\n",
      " 0.196875 0.759375 0.825    0.80625  0.65     0.840625]\n",
      "mean_acc: 0.6337499999999999\n",
      "train_size= 3\n",
      "time = 165.51607608795166  s\n",
      "[0.925   0.9375  0.7875  0.7875  0.9     0.7375  0.7875  0.6     0.9625\n",
      " 0.5875  0.24375 0.7625  0.84375 0.725   0.675   0.65    0.35625 0.91875\n",
      " 0.9     0.66875 0.81875 0.83125 0.975   0.75625 0.78125 0.35625 0.76875\n",
      " 0.7375  0.75625 0.93125 0.49375 0.375   0.5625  0.8375  0.825   0.80625\n",
      " 0.85625 0.2625  0.66875 0.71875 0.34375 0.7     0.53125 0.3     0.70625\n",
      " 0.6375  0.35625 0.85625 0.825   0.6625  0.6125  0.7875  0.8     0.61875\n",
      " 0.3125  0.8875  0.86875 0.78125 0.25    0.7625  0.3     0.76875 0.9375\n",
      " 0.73125 0.225   0.8375  0.9     0.85625 0.76875 0.8875 ]\n",
      "mean_acc: 0.6955357142857143\n"
     ]
    }
   ],
   "source": [
    "Aug_size = [3,5,6]\n",
    "acc_all = np.zeros((70,3))\n",
    "for i_train in range(3):\n",
    "    print('train_size=',i_train+1)\n",
    "    c = time.time()\n",
    "    acc = Parallel(n_jobs=-1)(delayed(beta_TDCA_Aug)(idx_num, n_train=i_train+1, t_task=0.5, n_Aug=Aug_size[i_train]) for idx_num in range(70))\n",
    "    acc =  np.array(acc)\n",
    "    acc_all[:,i_train] = acc\n",
    "    e = time.time()\n",
    "    print('time =', e - c,' s')\n",
    "    print(acc)\n",
    "    print('mean_acc:',np.mean(acc))\n",
    "sio.savemat(r'demo_beta_TDCA_withSAME.mat', {'acc': acc_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
